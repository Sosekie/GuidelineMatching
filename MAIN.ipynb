{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m run_pipeline_1\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Define file paths\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     file_path_excel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2024-09-27_Food_Waren-und_Dienstleistungsgruppe_V_4.0.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mf:\\GuidelineMatching\\pipeline\\pipeline_1.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, util\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_and_process_data, ensure_directories_exist\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msemantic_search_global\u001b[39m(input_queries, corpus_embeddings, corpus_texts, model, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\GuidelineMatching_3.10\\lib\\site-packages\\sentence_transformers\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\GuidelineMatching_3.10\\lib\\site-packages\\sentence_transformers\\backend.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Literal\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m disable_datasets_caching, is_datasets_available\n\u001b[0;32m     13\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\GuidelineMatching_3.10\\lib\\site-packages\\sentence_transformers\\util.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download, snapshot_download\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\GuidelineMatching_3.10\\lib\\site-packages\\torch\\__init__.py:262\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    260\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 262\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Anaconda\\envs\\GuidelineMatching_3.10\\lib\\site-packages\\torch\\__init__.py:238\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    236\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 238\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mkernel32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pipeline.pipeline_1 import run_pipeline_1\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    file_path_excel = \"2024-09-27_Food_Waren-und_Dienstleistungsgruppe_V_4.0.xlsx\"\n",
    "    file_paths_csv = [\n",
    "        \"DATA/1_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/2_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/4_Harmonisiert_ausschreibung.csv\"\n",
    "    ]\n",
    "    embedding_cache_path = \"embedding/Pipeline_1_embeddings_cache.pkl\"\n",
    "    result_path = \"result/Pipeline_1.csv\"\n",
    "\n",
    "    # Set hyperparameters\n",
    "    top_k = 10  # Number of top matches to retrieve\n",
    "\n",
    "    # Run Pipeline 1\n",
    "    run_pipeline_1(file_path_excel, file_paths_csv, embedding_cache_path, result_path, top_k=top_k)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.pipeline_2 import run_pipeline_2\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    file_path_excel = \"2024-09-27_Food_Waren-und_Dienstleistungsgruppe_V_4.0.xlsx\"\n",
    "    file_paths_csv = [\n",
    "        \"DATA/1_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/2_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/4_Harmonisiert_ausschreibung.csv\"\n",
    "    ]\n",
    "    embedding_cache_path = \"embedding/Pipeline_2_embeddings_cache.pkl\"\n",
    "    result_path = \"result/Pipeline_2.csv\"\n",
    "\n",
    "    # Set hyperparameters\n",
    "    top_k = 10  # Number of top reranked matches to retrieve\n",
    "    bi_top_k = 32  # Number of top Bi-Encoder matches before reranking\n",
    "\n",
    "    # Run Pipeline 2\n",
    "    run_pipeline_2(file_path_excel, file_paths_csv, embedding_cache_path, result_path, top_k=top_k, bi_top_k=bi_top_k)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.baseline import run_baseline\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    file_path_excel = \"2024-09-27_Food_Waren-und_Dienstleistungsgruppe_V_4.0.xlsx\"\n",
    "    file_paths_csv = [\n",
    "        \"DATA/1_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/2_Harmonisiert_pflichtenheft.csv\",\n",
    "        \"DATA/4_Harmonisiert_ausschreibung.csv\"\n",
    "    ]\n",
    "    result_path = \"result/Baseline.csv\"\n",
    "\n",
    "    # Set hyperparameters\n",
    "    model_name = \"gpt-4o-mini\"  # Specify GPT model\n",
    "    top_k = 10  # Number of top matches to retrieve\n",
    "\n",
    "    # Run Baseline Pipeline\n",
    "    run_baseline(file_path_excel, file_paths_csv, result_path, model_name=model_name, top_k=top_k)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.pipeline_3 import run_pipeline_3\n",
    "import nest_asyncio\n",
    "\n",
    "# 允许嵌套事件循环\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def main():\n",
    "    # Define file paths\n",
    "    file_path_excel = \"2024-09-27_Food_Waren-und_Dienstleistungsgruppe_V_4.0.xlsx\"\n",
    "    file_paths_csv = \"grouped_result.csv\"\n",
    "    result_path = \"result/matching_matrix.npy\"\n",
    "    embedding_cache_path = \"embedding/Pipeline_2_embeddings_cache.pkl\"\n",
    "\n",
    "    # Set hyperparameters\n",
    "    model_name = \"gpt-4o-mini\"  # Specify GPT model\n",
    "\n",
    "    # Run Baseline Pipeline\n",
    "    run_pipeline_3(file_path_excel, file_paths_csv, embedding_cache_path, result_path, gpt_model_name=model_name)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 79)\n",
      "row_match is 0 at row 17.\n",
      "row_match is 0 at row 18.\n",
      "row_match is 0 at row 20.\n",
      "row_match is 0 at row 24.\n",
      "0.41185897435897434\n"
     ]
    }
   ],
   "source": [
    "from pipeline.evaluate import recall_k\n",
    "import numpy as np\n",
    "\n",
    "target_matrix_path = 'matched_table.csv'\n",
    "target_matrix = np.loadtxt(target_matrix_path, delimiter=\",\", dtype=int)\n",
    "\n",
    "predicted_matrix_path = \"result/p3_matching_matrix.npy\"\n",
    "predicted_matrix = np.load(predicted_matrix_path)\n",
    "\n",
    "score = recall_k(predicted_matrix[:30], target_matrix[:30])\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_matrix_path = 'matched_table.csv'\n",
    "target_matrix = np.loadtxt(target_matrix_path, delimiter=\",\", dtype=int)\n",
    "\n",
    "predicted_matrix_path = \"result/p4_matching_matrix.npy\"\n",
    "predicted_matrix = np.load(predicted_matrix_path)\n",
    "\n",
    "score = recall_k(predicted_matrix[:30], target_matrix[:30])\n",
    "\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GuidelineMatching_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
